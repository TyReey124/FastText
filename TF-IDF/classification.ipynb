{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pymorphy3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    }
   ],
   "source": [
    "# Загрузка необходимых ресурсов\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Инициализация pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer()\n",
    "\n",
    "# Получение списка русских стоп-слов\n",
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    # Приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Токенизация\n",
    "    words = word_tokenize(text, language=\"russian\")\n",
    "    \n",
    "    # Удаление пунктуации и стоп-слов\n",
    "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "    \n",
    "    # Лемматизация\n",
    "    lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
    "    \n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для поиска по заголовку и получения определенных полей\n",
    "def get_fields_by_title(json_data, title):\n",
    "    for item in json_data['data']:\n",
    "        if item['title'] == title:\n",
    "            return {\n",
    "                \"question\": f\"{title}\",\n",
    "                \"answer\": item.get(\"description\"),\n",
    "                \"url\": item.get(\"url\"),\n",
    "            }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем путь к файлу JSON\n",
    "json_file_path = './data-base/dataset.json'\n",
    "\n",
    "# Открываем файл JSON и загружаем данные\n",
    "with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "# Извлекаем все значения 'title' в массив\n",
    "titles = [item['title'] for item in dataset['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(data, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Массив для лемматизированных вопросов\n",
    "lemmatized_questions = []\n",
    "\n",
    "# Цикл для лемматизации каждого вопроса\n",
    "for question in titles:\n",
    "    lemmatized_question = lemmatize_text(question)\n",
    "    lemmatized_questions.append({\"question\": question, \"lemmatized_question\": lemmatized_question})\n",
    "\n",
    "questions = [item[\"lemmatized_question\"] for item in lemmatized_questions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Токенизация и векторизация\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание функции для нахождения ближайшего вопроса и всех вопросов на небольшом расстоянии от него\n",
    "def find_closest_questions(user_question, extra_threshold=0.01):\n",
    "    lemmatized_user_question = lemmatize_text(user_question)\n",
    "    user_question_vec = vectorizer.transform([lemmatized_user_question])\n",
    "    similarities = cosine_similarity(user_question_vec, X).flatten()\n",
    "    \n",
    "    # Находим индекс ближайшего вопроса\n",
    "    closest_idx = np.argmax(similarities)\n",
    "    max_similarity = similarities[closest_idx]\n",
    "    \n",
    "    # Устанавливаем пороговое значение\n",
    "    threshold = max_similarity - extra_threshold\n",
    "    \n",
    "    # Находим все вопросы, которые находятся в пределах порогового значения\n",
    "    closest_indices = np.where(similarities >= threshold)[0]\n",
    "    return closest_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers(user_question, extra_threshold=0.01, max_answers=7):\n",
    "    closest_indices = find_closest_questions(user_question, extra_threshold)\n",
    "    return [lemmatized_questions[idx][\"question\"] for idx in closest_indices[:max_answers]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: какая налоговая ставка при оформлении ИП\n",
      "Ответы:\n",
      "[{'question': 'Какие документы нужны для оформления ИП?', 'answer': 'Для регистрации через сервис Тинькофф достаточно российского паспорта и СНИЛС. Как заполнить анкету для регистрации ИП Если регистрируетесь самостоятельно в налоговой, понадобятся следующие документы: заявление о регистрации в качестве ИП; копия российского паспорта; квитанция об уплате госпошлины, если регистрируетесь не через сайт, а лично или отправляете документы почтой.', 'url': 'https://www.tinkoff.ru/business/help/registration/registration/register-ip/opening-conditions/?card=q4'}]\n"
     ]
    }
   ],
   "source": [
    "# Пример использования\n",
    "user_question = \"какая налоговая ставка при оформлении ИП\"\n",
    "answers = get_answers(user_question, extra_threshold=0.1)\n",
    "print(f\"Вопрос: {user_question}\\nОтветы:\")\n",
    "\n",
    "prompt = []\n",
    "\n",
    "for answer in answers:\n",
    "    result = get_fields_by_title(dataset, answer)\n",
    "    prompt.append(result)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = './querry/prompt.json'\n",
    "\n",
    "# Запись обновленных данных в JSON-файл\n",
    "save_json(prompt, json_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
